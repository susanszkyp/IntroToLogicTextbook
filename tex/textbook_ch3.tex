\chapter{Semantics}

If you have already taken an introductory logic course, you may remember talk of entailment, and in connection, validity. In particular, taking an argument with some premises and a conclusion, validity was probably specified along the following lines: if the premises are true, the conclusion must also be true. Then, it was said, the premises `entail' the conclusion. 

But so far, we have only been dealing with formal languages as being made up of various sequences of meaningless symbols, according to various rules. Where does truth enter the picture? 

The answer is: semantics. In some sense, syntax and semantics are two sides of the same coin. Syntax specifies the way primitive symbols may be combined to form more complex expressions. Semantics, on the other hand, specifies how the meaning of more complex expressions can be computed from the meaning of primitive symbols. As we shall see, the rules of computation for the `values' of expressions will match the rules of formulation of expressions in our syntax. The idea underlying this is called `compositionality'. As simpler syntactic expressions compose more complex ones, so the meanings of these simpler syntactic expressions compose the meanings of more complex ones. Then, just as being a formula is precisely definable, meaning will be too. 

Once we have a grasp on the rules of meaning for $\mathcal{L}_0$, we can start designating some formulas of the language as `true', and some as `false', based on their respective meaning (and some other stuff, which we shall get to in due course). We will also see later on how the truth values of various sets of formulas relate to the truth values of other sets of formulas. From this, it will take just one additional step to specify how sometimes, some premises being true \textit{ensures} that the conclusion \textit{must} also be true. 

\fpboxstar{
From now on, until further notice, we will only be discussing the language $\mathcal{L}_0$, the language of zeroth-order logic, and simple fragments of it with only a few predicates and connectives. In the latter cases, you can always imagine that the rest of the language is also dealt with in some way or another similar to the ones presented. 
}

As noted above, semantics proceeds along the lines of syntax. In the syntax of $\mathcal{L}_0$, we have two types of base symbols: constants and predicates. As we have seen, every \textit{atomic} formula is made up of an $n$-place predicate, followed by $n$ constant symbols, in brackets, separated by commas. So in order to give truth-values to our atomic formulas, we first have to specify the meaning of constants and predicates. Then, we shall be able to \textit{compute} the truth-values of our atomic formulas from this. In turn, this will allow us to \textit{compute} the truth-values of our more complex formulas. 

\section{Constants}

Let's start with the simplest case; constants. Constants in our language $\mathcal{L}_0$ function like names. In particular, their meaning is just what they designate, or refer to. 

Note that we are talking about two distinct `planes' here. On the side of syntax, we have symbols without meaning. On the side of semantics, we have things assigned to them. Giving a semantics to our language is then bridging a gap, assigning things to our constants. These things are not symbols, they are the things themselves. You may have heard of the phrase `domain of discourse'. The domain of discourse, or simply domain, is just the \textit{set} of things we may talk about using a language.

\begin{exc}
How does this notion of a domain relate to the notions of domain and codomain regarding functions?
\end{exc}

 In particular:

\begin{center}
\begin{tabular}{rcl}
	\textsc{Constants} & $\mapsto$ & \textsc{Domain}\\\hline
	constant & $\mapsto$ & thing
\end{tabular}
\end{center}

You may remember the symbol $\mapsto$ from our discussion of set theory. It designates that a certain function outputs the right-hand side value given the value on the left-hand side. And indeed, giving meaning to our language is just specifying a function that, in part, assigns to every constant a thing (sometimes called an `object') from our domain. Like this:
\begin{center}
	\begin{tabular}{rcl}
		\textsc{Constants} & $\mapsto$ & \textsc{Domain}\\\hline
		$\cons{1}$ & $\mapsto$ & Robert J. Oppenheimer
	\end{tabular}
\end{center}

According to the above specification, the constant $\cons{1}$ designates Oppenheimer in our language. Note that while $\cons{1}$ is a symbol of the language, Oppenheimer, the thing (`person') it designates is, again, the real thing. We can continue assigning things to our constants to our own delight. For example, we can specify:
\begin{center}
	\begin{tabular}{rcl}
		\textsc{Constants} & $\mapsto$ & \textsc{Domain}\\\hline
		$\cons{1}$ & $\mapsto$ & Robert J. Oppenheimer\\
		$\cons{2}$ & $\mapsto$ & Taylor Swift\\
		$\cons{3}$ & $\mapsto$ & the number $5$\\
		$\cons{4}$ & $\mapsto$ & World War II\\
		& \vdots & 
	\end{tabular}
\end{center}

As you can see, there is no limit to what a constant can designate. Thing and object is meant here in a very loose sense. It can be a person, a physical object, an event, an idea, whatever you want. 

Let's recap. We have constants, which are symbols of our language. We have objects, in a loose sense, which are members of the domain of discourse. And we have a function, which assigns to each constant a member of the domain of discourse, as illustrated in the table above. This function is usually called an \textit{interpretation function}, since it interprets the uninterpreted symbols of a language. We can make this more precise as follows:

\begin{defn}
A domain (of discourse) is any set $\mathbf{D}$. An interpretation function for the constants of $\mathcal{L}_0$, denoted by $\mathsf{CONS}_{\mathcal{L}_0}$, (relative to $\mathbf{D}$) is a function $\mathbf{I}: \mathsf{CONS}_{\mathcal{L}_0} \to \mathbf{D}$. If $c$ is a constant of $\mathcal{L}_0$, then $\mathbf{I}(c) \in \mathbf{D}$, and is what $c$ \textit{designates}, \textit{denotes} or \textit{refers to}. Alternatively, we may say $\mathbf{I}(c)$ is the \textit{value} of the symbol $c$. 
\end{defn}

As you can see, interpretations are functions from the set of all constants to the domain. This means that to each constant, only one member of the domain corresponds. So unlike with real names like `Peter', which may designate many different people, a constant of $\mathcal{L}_0$ designates only one. On the other hand, the function $\mathbf{I}$ need not be one-to-one. This means that some distinct constants may designate the same thing, just like `Miley Stewart' and `Hannah Montana' designate the same person (in the hit TV show \textit{Hannah Montana}). It also doesn't need to be onto, so that some members of the domain $\mathbf{D}$ may go nameless. Like the lack of bijectivity, this is also natural, since many things do not have names in the real world. Just think of your left sock that fell behind the machine at the laundry. 

Having constants or names that refer to things is the first step towards giving meaning to our expressions, but it is not enough to get us to truth. Names, by themselves, are neither true nor false, they just refer. The other ingredient we need is giving meaning to our \textit{predicates}.

\clearpage

\section{Predicates} 

Predicates in logic are used to express \textit{properties} of objects or \textit{relations} between them. Again, properties and relations are meant here in a very loose sense, and their representation, in set theory, is very minimal in detail. 

\subsection{... of 1-place}

Suppose you want your $1$-place predicate $\pred{1}{1}$ in $\mathcal{L}_0$ to express the property `is a physicist'. We already introduced a domain of discourse, or domain, $\mathbf{D}$ about which are language should be about. So given our domain, how do we capture that $\pred{1}{1}$ should have the meaning `is a physicist'? Well, we can specify a subset of the domain $\mathbf{D}$, let's call it $\mathbf{P}$, which consists of just the physicists in our domain. In set-builder notation, we can say: 
\[
\mathbf{P}=\set{x\mid x\in \mathbf{D} \text{ and } x \text{ is a physicist}}
\]
$\mathbf{P}$ here is a subset of the domain $\mathbf{D}$, since by definition, every $x \in \mathbf{P}$ is also in $\mathbf{D}$. Moreover, it only includes those members of the domain that are physicists. That is, the set of physicists in the domain. This may be called the \textit{property} `is a physicist', as we noted in the last chapter. Then, we can use the interpretation function to connect our $1$-place \textit{predicate} to the \textit{property} (subset of the domain). 

Again, represented in a figure: 

\begin{center}
	\begin{tabular}{rcl}
		$1$-\textsc{place predicates} & $\mapsto$ & \textsc{Subsets of Domain (properties)}\\\hline
		$1$-place predicate & $\mapsto$ & set of things
	\end{tabular}
\end{center} 

And in particular: 

\begin{center}
	\begin{tabular}{rcl}
		$1$-\textsc{place predicates} & $\mapsto$ & \textsc{Subsets of Domain (properties)}\\\hline
		$\pred{1}{1}$ & $\mapsto$ & $\mathbf{P}$ (`is a physicist')
	\end{tabular}
\end{center} 

Again, the meaning of our predicates can be anything, as long as it is a property in the domain, that is, a subset of things of the domain. For example, it can be the set of things (of the domain $\mathbf{D}$) that are singers (the property of being a singer), the set of things that are numbers (the property of being a number), the set of things that are world wars (the property of being a world war), and so on. You can even have properties that only have one member, like `is the first female artist with four Top 10 albums at once'. 

\begin{center}
	\begin{tabular}{rcl}
		$1$-\textsc{place predicates} & $\mapsto$ & \textsc{Subsets of Domain (properties)}\\\hline
		$\pred{1}{1}$ & $\mapsto$ & $\mathbf{P}$ (`is a physicist')\\
		$\pred{1}{2}$ & $\mapsto$ & $\mathbf{S}$ (`is a singer')\\
		$\pred{1}{3}$ & $\mapsto$ & $\mathbf{N}$ (`is a number')\\
		$\pred{1}{4}$ & $\mapsto$ & $\mathbf{W}$ (`is a world war')\\
		& $\vdots$ & 
	\end{tabular}
\end{center} 

\subsection{... of 2-places}

The above approach takes care of our $1$-place predicates. But predicates can come with more places (the superscript for $\mathfrak{P}$). Suppose you want to assign meaning to a $2$-place predicate $\pred{2}{1}$, and in particular, you want it to mean `$x$ loves $y$'. Here, a set will not do, since we want to capture a \textit{relation}, not a \textit{property}. In particular we want to capture that a person is in the relation of loving another person (or thing in general). 

If you think back to our discussion of set theory, you already know how to do this. Instead of a set of objects, you can take a \textit{set of pairs} here, that represents two objects of the domain standing in the loving relation. Once again, we may introduce a relation $\mathbf{L}$ on the domain, and specify it as such: 
\[
\mathbf{L}=\set{\oset{x, y} \mid x,y \in \mathbf{D} \text{ and } x\text{ loves }y} 
\]
So $\mathbf{L}$ here is the set of pairs such that the first member of each pair loves the second member of that pair. So if our domain includes Julie and Jane, and Julie loves Jane, but Jane does not love Julie, we would have that $\oset{Julie, Jane} \in \mathbf{L}$, but $\oset{Jane, Julie} \notin \mathbf{L}$. So again:

\begin{center}
	\begin{tabular}{rcl}
		$2$-\textsc{place predicates} & $\mapsto$ & \textsc{Sets of Pairs of Domain ($2$-place relations)}\\\hline
		$2$-place predicate & $\mapsto$ & pairs of things
	\end{tabular}
\end{center} 

And in particular: 

\begin{center}
	\begin{tabular}{rcl}
		$2$-\textsc{place predicates} & $\mapsto$ & \textsc{Sets of Pairs of Domain ($2$-place relations)}\\\hline
		$\pred{2}{1}$ & $\mapsto$ & $\mathbf{L}$ (`loves')
	\end{tabular}
\end{center} 

Again, you can introduce whatever relation you want here, as long as it can be represented by a set of pairs of members of the domain. For example, `is the favorite number of', `is a sibling of', `stands 2 feet to the right of', and so on. That is: 

\begin{center}
	\begin{tabular}{rcl}
		$2$-\textsc{place predicates} & $\mapsto$ & \textsc{Sets of Pairs of Domain ($2$-place relations)}\\\hline
		$\pred{2}{1}$ & $\mapsto$ & $\mathbf{L}$ (`loves')\\
		$\pred{2}{2}$ & $\mapsto$ & $\mathbf{F}$ (`is the favorite number of')\\
		$\pred{2}{3}$ & $\mapsto$ & $\mathbf{B}$ (`is a sibling of')\\
		$\pred{2}{4}$ & $\mapsto$ & $\mathbf{R}$ (`stands 2 feet to the right of')
	\end{tabular}
\end{center} 

In each case, $\mathbf{L}$, $\mathbf{F}$, $\mathbf{B}$, $\mathbf{R}$ are just sets of pairs representing all pairs of members of the domain that are in the specified relation. 

Notice that each of these binary relations have, either on the left or the right side, a member of $\mathbf{D}$, the domain. By the Cartesian product of $\mathbf{D}$ with itself once, i.e., $\mathbf{D} \times \mathbf{D}$ or $\mathbf{D}^2$, we can get the set of \textit{all} pairs of members of $\mathbf{D}$. Now relations on $\mathbf{D}$ will be subsets of $\mathbf{D}^2$, since each will be either the universal relation on $\mathbf{D}$, the empty set, or somewhere in between. In the above example, $\oset{Julie, Jane} \in \mathbf{L}$, but $\oset{Jane, Julie} \notin \mathbf{L}$, so $\mathbf{L}$ is a non-empty proper subset of $\mathbf{D}^2$.

\fpboxstar{Note that it is very important to be clear about the directionality of a relation. For example, we may have a predicate with assigned meaning `loves'. But we may also have a predicate with assigned meaning `is loved by'. Now, if the relation $\mathbf{L}$ is the relation `loves', and $\mathbf{L}'$ is the relation `is loved by', then each pair will be reversed relative to the other one. For example, if $\oset{Julie, Jane} \in \mathbf{L}$, but $\oset{Jane, Julie} \notin \mathbf{L}$, then $\oset{Julie, Jane} \notin \mathbf{L}'$, but $\oset{Jane, Julie} \in \mathbf{L}$, since $x$ loves $y$ if, and only if, $y$ is loved by $x$. That is, if Julie loves Jane but Jane does not love Julie, then Jane is loved by Julie but Julie is not loved by Jane.}

\subsection{... of \emph{n}-places}

You may see a pattern here. Predicates of $1$-place (unary predicates) were interpreted as sets. Predicates of $2$-places (binary predicates) were interpreted as $2$-place relations. But of course, our language has predicates of every arity (every number of `place'), and to each, we may want to attribute some meaning. Well, this is not hard to do, since for any $n$-place predicate, we can assign an $n$-place relation. The important thing is just that if a predicate is of form $\pred{n}{k}$, then its meaning must agree with $n$, so it has to be a set of $n$-tuples. 

\begin{exc}
Give a natural example of a $3$-place, $4$-place, and $5$-place relation. 
\end{exc}

Following our handy figure, we have:

\begin{center}
	\begin{tabular}{rcl}
		$n$-\textsc{place predicates} & $\mapsto$ & \textsc{Sets of $n$-tuples of Domain ($n$-place relations)}\\\hline
		$n$-place predicate & $\mapsto$ & set of $n$-tuples ($n$-place relation)
	\end{tabular}
\end{center} 

Making it a bit more concrete, but still quite abstract, we have: 

\begin{center}
	\begin{tabular}{rcl}
		$n$-\textsc{place predicates} & $\mapsto$ & \textsc{Sets of $n$-tuples of Domain ($n$-place relations)}\\\hline
		$\pred{1}{1}$ & $\mapsto$ & $\mathbf{R}_1 \subseteq \mathbf{D}$\\
		& $\vdots$ &\\
		$\pred{2}{1}$ & $\mapsto$ & $\mathbf{R}_i \subseteq \mathbf{D}^2$\\
		& $\vdots$ &\\
		$\pred{n}{1}$ & $\mapsto$ & $\mathbf{R}_k \subseteq \mathbf{D}^n$\\
		& $\vdots$ &\\
	\end{tabular}
\end{center} 

We can then extend our interpretation function $\mathbf{I}$ to cover now not only constants, but predicates as well. 

\begin{defn}
A domain (of discourse) is any set $\mathbf{D}$. An interpretation function for the predicates of $\mathcal{L}_0$, denoted by $\mathsf{PRED}_{\mathcal{L}_0}$, (relative to $\mathbf{D}$) is a function $\mathbf{I}$ such that for each predicate $\pred{n}{k}$, $\mathbf{I}(\pred{n}{k})=\mathbf{R}$ for some $\mathbf{R} \subseteq \mathbf{D}^n$ (the Cartesian product of $\mathbf{D}$ taken $n$-times with itself). 
\end{defn}

In fact, we can put together our definition of an interpretation function for constants, and our definition of an interpretation function for predicates, into one definition. We can also introduce a new notion; \textit{structure}. Structure is just a shorthand for what we have been saying over and over again; that when give meaning to our expressions, we do it with an interpretation function $\mathbf{I}$ against the backdrop of a domain $\mathbf{D}$. So a structure $\mathbf{S}$ is just a pair $\oset{\mathbf{D}, \mathbf{I}}$ where $\mathbf{D}$ is the domain, and $\mathbf{I}$ is the interpretation function under consideration. With this in hand, we can say: 

\begin{defn} \label{structure}
A structure $\mathbf{S}$ is a pair $\oset{\mathbf{D}, \mathbf{I}}$, where $\mathbf{D}$ is any set, and $\mathbf{I}$ is a function from the constants and predicates of $\mathcal{L}_0$ (i.e., $\mathsf{CON}_{\mathcal{L}_0} \cup \mathsf{PRED}_{\mathcal{L}_0}$) such that:
%
\begin{enumerate}
	\item if $c$ is any constant of $\mathcal{L}_0$, $\mathbf{I}(c) \in \mathbf{D}$, and;
	\item if $P^n$ is any predicate  of arity $n$ ($n$-place predicate) of $\mathcal{L}_0$, $\mathbf{I}(P^n)=\mathbf{R}$, where $\mathbf{R} \subseteq \mathbf{D}^n$. 
\end{enumerate}
\end{defn}

As you can see, logicians can say a lot of stuff in very few words. This may seem intimidating at first. But remember that all these terse definitions hide quite intuitive ideas. We spent a lot of time pondering these ideas so that you can read and understand the definition above, and the nuances and niceties it expresses so elegantly. This also gives you a very important skill: to go further. In more advanced logic textbooks, you won't find such long explanations as we have given. But now you won't need them either!\footnote{Indeed, this is why they don't include them...}

\subsubsection{A brief return to our language specification}

Indeed, now that we are familiar with a lot more machinery than before, we can give a definition of our language in a manner that is a lot more succint. 

\begin{defn} \label{language}
Let $\mathsf{ALPH}_{\mathcal{L}_0}$ be the alphabet of $\mathcal{L}_0$, specified as before, and thought of as forming a set. In particular, let $\mathsf{PRED}_{\mathcal{L}_0} \subseteq \mathsf{ALPH}_{\mathcal{L}_0}$ and $\mathsf{CONS}_{\mathcal{L}_0} \subseteq \mathsf{ALPH}_{\mathcal{L}_0}$, and such that:

\begin{enumerate}
	\item $\mathsf{CONS}_{\mathcal{L}_0}=\set{\cons{n} \mid n \in \mathbb{N}}$, and;
	\item $\mathsf{PRED}_{\mathcal{L}_0}=\set{\pred{n}{k} \mid n, k \in \mathbb{N}}$.
\end{enumerate}

The set of (well-formed) formulas of $\mathcal{L}_0$ is the smallest set $\mathsf{FORM}_{\mathcal{L}_0}$ such that:
%
\begin{enumerate}
	\item if $P$ is a predicate of arity $n$ in $\mathsf{PRED}_{\mathcal{L}_0}$, and $c_1, c_2, ..., c_n$ are (not necessarily distinct) constants in $\mathsf{CONS}_{\mathcal{L}_0}$, then $P(c_1, ..., c_n) \in \mathsf{FORM}_{\mathcal{L}_0}$, and is an \textit{atomic} formula;
	\item if $X$ and $Y$ are in $\mathsf{FORM}_{\mathcal{L}_0}$, then:
		\begin{enumerate}
		\item $\neg X \in \mathsf{FORM}_{\mathcal{L}_0}$;
		\item $(X \wedge Y) \in \mathsf{FORM}_{\mathcal{L}_0}$;
		\item $(X \vee Y) \in \mathsf{FORM}_{\mathcal{L}_0}$; and
		\item $(X \rightarrow Y) \in \mathsf{FORM}_{\mathcal{L}_0}$.
		\end{enumerate}
\end{enumerate}
\end{defn}

Again, a few weeks ago, this may have seemed extremely cryptic and impossible to comprehend, but now you are familar with all the different ideas underlying this definition, and can understand its intended meaning. 

\fpboxstar{
In fact, when I was studying philosophy as an undergrad, I was reading papers from Russell, Quine, and others, and I really wanted to understand what they were saying. So I went and bought myself a book on semantics. I opened up the first page, and definitions not unlike \ref{language} and \ref{structure} greeted me. Unlike you, I did not have a textbook like this, so I had no idea what was going on. Needless to say, my foray into semantics stopped right there, and did not continue for a few years. 
}

\section{Atomic formulas}

Remember that we started our discussion in this chapter by setting our aim at assigning truth values to formulas. Once we have assigned meaning to our constants and predicates, we are in the position to do just that! Again, the basic idea underlying the mathematical machinery is not very difficult to grasp, but it is a very fundamental insight in several areas of thought, including philosophy, linguistics, and mathematics, and it was only precisely formulated around the middle of the 20$^\text{th}$ century by the Polish logician Alfred Tarski.

We can illustrate this basic idea algorithmically, by looking at how one may go on calculating truth-values for atomic formulas, once a structure $\mathbf{S}$ is specified. Let's take some arbitrary constants from our language $\mathcal{L}_0$, using $a$, $b$, and $c$. Let's also take some arbitrary predicates of the language, using $P$, $Q$, and $R$. We can further specify that $P$ is of arity $1$, $Q$ is of arity $2$, and $R$ is of arity $3$. 

Now let's take some rather arbitrary atomic formulas, let's say:
\begin{gather}
	P(a)\label{ex1}\\
	P(c)\label{ex2}\\
	Q(a, c)\label{ex3}\\
	Q(c, a)\label{ex4}\\
	R(a, b, c)\label{ex5}\\
	R(a, c, b)\label{ex6}
\end{gather}

What if I ask you to decide whether these formulas are true or false? In that case, you should say: I cannot do that, since you haven't given me a domain $\mathbf{D}$ and an interpretation $\mathbf{I}$ that would tell me what these formulas mean, and against what I should evaluate them! Relative to different structures, different atomic formulas may be true or false, so there is no way to answer this question without first specifying a structure $\mathbf{S}$. So let's do just that. 

Take a domain $\mathbf{D}=\set{\mathbf{a}, \mathbf{b}, \mathbf{c}, \mathbf{d}}$, and an interpretation function such that:

\begin{enumerate}
	\item $I(a)=\mathbf{a}$, $I(b)=\mathbf{b}$, $I(c)=\mathbf{c}$, $I(d)=\mathbf{d}$; \label{consin}
	\item \label{predin}
		\begin{enumerate}
	\item $I(P)=\{\mathbf{a}, \mathbf{d}\}$;
	\item $I(Q)=\set{\oset{\mathbf{a}, \mathbf{c}}, \oset{\mathbf{d}, \mathbf{a}}, \oset{\mathbf{a}, \mathbf{d}}}$;
	\item $I(R)=\set{\oset{\mathbf{a}, \mathbf{b}, \mathbf{c}}, \oset{\mathbf{b}, \mathbf{c}, \mathbf{b}}, \oset{\mathbf{b}, \mathbf{b}, \mathbf{b}}}$.
		\end{enumerate} 
\end{enumerate}

Call this the structure $\mathbf{S}$. Now we can ask: which of the formulas are true \textit{relative to} the structure $\mathbf{D}$? To answer this question, again, we need to do some very simple calculations. 

The basic idea is this. To each constant of the language, the interpretation function $I$ assigns a member of the domain (see \ref{consin} above). And to each predicate (of arity $n$), the interpretation function assigns a set of $n$-tuples (see \ref{predin} above).

Next, all you have to do is check the \textit{value} of a constant (or list of constants) under $I$, and compare it against the value of the relevant predicate under $I$. If the value of the constant (or sequence of constants) is in the value of the predicate under $I$, the atomic formula is true, otherwise, it is false. 

Take the formula $P(a)$ (the formula (\ref{ex1}) above). Is it true in $\mathbf{D}$? Well, we see that $I(a)=\mathbf{a}$. And we also see that $I(P)=\{\mathbf{a}, \mathbf{d}\}$. Since $I(a)$ (which is just $\mathbf{a}$) is \textit{in} the set $I(P)$, the atomic formula $P(a)$ is true. On the other hand, if we take $P(c)$ (the formula (\ref{ex2}) above), we see that $I(c)=\mathbf{c}$, and $\mathbf{c} \notin I(P)$, so $I(c) \notin I(P)$. So $P(c)$ is false in $\mathbf{D}$. 

This may seem a bit elaborate, but really, all you are doing is checking if the value of the constant under $I$ is in the set that is the value of the predicate $P$. 

There is a special way of representing the relation `the formula $X$ is true in the structure $\mathbf{S}$'. It is written like this: $\mathbf{S} \models X$. You can also read it as: $\mathbf{S}$ \textit{models} $X$. This is simply because $\mathbf{S}$ `models' a world in which $X$ would be true. So again, $\mathbf{S}\models P(a)$ ($\mathbf{S}$ models $P(a)$), but $\mathbf{S}\not\models P(c)$ ($\mathbf{S}$ does \textit{not} model $P(c)$).

Predicates with more than $1$ arity aren't more elaborate than this. The only difference is that now you have to check that the values of the constants under $I$ are in the value of the predicate \textit{as an $n$-tuple}, and of course, in the right order. 

Take $Q(a, c)$ (formula (\ref{ex3}) above). Again, $I(a)=\mathbf{a}$, and $I(c)=\mathbf{c}$, so the question is whether $\oset{\mathbf{a}, \mathbf{c}} \in I(Q)$. By definition, $I(Q)=\set{\oset{\mathbf{a}, \mathbf{c}}, \oset{\mathbf{d}, \mathbf{a}}, \oset{\mathbf{a}, \mathbf{d}}}$. So $\oset{\mathbf{a}, \mathbf{c}} \in I(Q)$. So $\mathbf{S} \models Q(a, c)$, or $Q(a,c)$ is true in $\mathbf{S}$. On the other hand, $Q(c, a)$ would make us consider wether $\oset{\mathbf{c}, \mathbf{a}} \in I(Q)$, which as you can see it is not. So $\mathbf{S}\not\models Q(c, a)$ (formula (\ref{ex4})), or $Q(c, a)$ is false in $\mathbf{S}$.

\begin{exc}
Determine whether the formulas $R(a, b, c)$ (\ref{ex5}) and $R(a, c, b)$ (\ref{ex6}) are true in $\mathbf{S}$. In each case, give a proof just like the ones above for (\ref{ex1}, \ref{ex2}, \ref{ex3}, and \ref{ex4}). \label{atomicvalue}
\end{exc} 

\begin{exc}
One of the members of the domain does not have a name! That means that unfortunately, we cannot talk about, even if the object itself shows up in our properties and relations. Which member is this?
\end{exc}

Note that we can also take the reverse of this question. Namely, instead of considering whether a given formula is true in $\mathbf{S}$, we can start with $\mathbf{S}$ and consider which formulas are true in it. This is really just the reverse reasoning. For example, you can inspect $I(R)$, and see that $I(R)=\set{\oset{\mathbf{a}, \mathbf{b}, \mathbf{c}}, \oset{\mathbf{b}, \mathbf{c}, \mathbf{b}}, \oset{\mathbf{b}, \mathbf{b}, \mathbf{b}}}$. You can also see that $I(b)=\mathbf{b}$. Now, since $\oset{\mathbf{b}, \mathbf{b}, \mathbf{b}} \in I(R)$, that means $R(b, b, b)$ is true in $\mathbf{S}$, or $\mathbf{S} \models R(b, b, b)$. 

\begin{exc}
Find an atomic formula $X$ distinct from all the above such that $\mathbf{S} \not\models X$. Don't forget to give an appropriate proof as to why that is the case. 
\end{exc}

Note that the structure above was rather trivial and intuitive. But we can give a completely different structure $\mathbf{N}$ and ask again whether the above formulas are true or false in that structure. Let $\mathbf{N}=\oset{\mathbb{N}^+, I'}$. In other words, the structure $S$ is such that its domain $\mathbf{D}=\mathbb{N}^+$, the set of all positive natural numbers. 

We now specify a new interpretation $I'$, that interprets our formulas in $\mathbf{N}$. 

\begin{enumerate}
	\item $I'(a)=1$, $I'(b)=2$, $I'(3)=c$;
	\item 
		\begin{enumerate}
		\item $I'(P)=\{n \mid n\text{ is even}\}$;
		\item $I'(Q)=\set{\oset{n, k} \mid n < k}$;
		\item $I'(R)=\set{\oset{n, k, i} \mid n+k=i}$. 
		\end{enumerate}
\end{enumerate}

In other words, under $I'$, $P(x)$ means `$x$ is even', $Q(x, y)$ means `$x$ is less than $y$', and $R(x, y, z)$ means `$x+y=z$. And $a$ under $I'$ means $1$, $b$ means $2$, and so on.

Then, we can consider $P(a)$ and $P(c)$ again. Well, doing the calculations, neither $1$ nor $3$ are even numbers, so $P(a)$ and $P(c)$ are both false. 

On the other hand, one of $Q(a, c)$ and $Q(c, a)$ must be true, since $a$ and $c$ mean distinct numbers. In particular, $Q(a, c)$ means $1$ is smaller than $3$, and $Q(c, a)$ means $3$ is smaller than $1$ under $I'$. So $\mathbf{N}\models Q(a, c)$, but not $Q(c, a)$. 

And incidentally, $R(a, b, c)$ is true in $\mathbf{N}$, since $1+2=3$. But $1+3\neq 2$, so $R(a, c, b)$ is false in $\mathbb{N}$. 

\begin{exc}
The above proofs are sketchy, referring to `doing the calculations' and `meanings'. Write them down in a precise manner, following the style of the proofs for $\mathbf{S}$. 
\end{exc}

\subsubsection{Putting it all together}

Now we are in the position to further extend our definition to include assigning truth values to atomic formulas. It goes like this: 

\begin{defn} \label{atomicin}
A structure $\mathbf{S}$ is a pair $\oset{\mathbf{D}, \mathbf{I}}$, where $\mathbf{D}$ is any set, and $\mathbf{I}$ is a function from the constants and predicates of $\mathcal{L}_0$ (i.e., $\mathsf{CON}_{\mathcal{L}_0} \cup \mathsf{PRED}_{\mathcal{L}_0}$) such that:
	%
\begin{enumerate}
	\item if $c$ is any constant of $\mathcal{L}_0$, $\mathbf{I}(c) \in \mathbf{D}$, and;
	\item if $P^n$ is any predicate  of arity $n$ ($n$-place predicate) of $\mathcal{L}_0$, $\mathbf{I}(P^n)=\mathbf{R}$, where $\mathbf{R} \subseteq \mathbf{D}^n$. 
\end{enumerate}
%
For each atomic formula $P^n(c_1, ..., c_n)$ of the language $\mathcal{L}_0$, we have:
\[
\mathbf{S} \models P(c_1, ..., c_n)\text{ if, and only if, }\oset{I(c_1), ..., I(c_n)} \in I(P^n).
\]
If $\mathbf{S} \models P(c_1, ..., c_n)$, we say $\mathbf{S}$ \textit{models} $P(c_1, ..., c_n)$, or \textit{is a model of} $P(c_1, ..., c_n)$. Alternatively, we say $P(c_1, ..., c_n)$ is \textit{true in} $\mathbf{S}$. 
\end{defn}

\section{Complex formulas}

We are now in the position to give truth-values to our more complex formulas, based on the values of the atomic formulas. Again, everything is relativized to a certain structure, since that is how we can assign truth-values to the atomic ones.

This is done by invoking the concept of a truth-function. A truth-function is just a function that takes one or more truth-values, and outputs a single truth-value. The meaning of our connectives are truth-functions in this sense. They operate on the values of their constituent formulas, and output another truth-value. 

There are several ways to formula this idea. First, one may specify these truth-values in terms of truth ($T$) and falsity ($F$), and a function $v: \mathsf{FORM}_{\mathcal{L}_0} \to \set{T, F}$ for any formula $X$, $Y$, like this:

\begin{enumerate}
	\item $v(\neg X)=T$ if, and only if, $v(X)=f$;
	\item $v(X \wedge Y)=T$ if, and only if, $v(X)=T$ and $v(Y)=T$;
	\item $v(X \vee Y)=T$ if, and only if, $v(X)=T$ or $v(Y)=T$ (or both);
	\item $v(X \rightarrow Y)=T$ if, and only if, if $v(X)=T$, then $v(Y)=T$. 
\end{enumerate}

Now usually, these are represented in truth-tables, which are really just tables representing the above truth-function, $v$, by listing all its input-output pairs one by one. In particular:

\begin{figure}[h]
\begin{center}
\begin{minipage}{0.25\textwidth}
\begin{tabular}{|c|c|c|}
	\hline
	$X$ & $Y$ & $X \wedge Y$\\ \hline
	$T$ & $T$ & $T$\\
	$T$ & $F$ & $F$\\
	$F$ & $T$ & $F$\\
	$F$ & $F$ & $F$\\ \hline
\end{tabular}
\end{minipage}
%
\begin{minipage}{0.25\textwidth}
\begin{tabular}{|c|c|c|}
	\hline
	$X$ & $Y$ & $X \vee Y$\\ \hline
	$T$ & $T$ & $T$\\
	$T$ & $F$ & $T$\\
	$F$ & $T$ & $T$\\
	$F$ & $F$ & $F$\\\hline
\end{tabular}
\end{minipage}
%
\begin{minipage}{0.25\textwidth}
\begin{tabular}{|c|c|c|}
	\hline
	$X$ & $Y$ & $X \rightarrow Y$\\ \hline
	$T$ & $T$ & $T$\\
	$T$ & $F$ & $F$\\
	$F$ & $T$ & $T$\\
	$F$ & $F$ & $T$\\ \hline
\end{tabular}
\end{minipage}
%
\begin{minipage}{0.20\textwidth}
\begin{tabular}{|c|c|}
	\hline
	$X$ & $\neg X$\\ \hline
	$T$ & $F$\\
	$F$ & $T$\\ \hline
\end{tabular}
\end{minipage}
\end{center}
\caption{Truth tables}
\label{tto}
\end{figure}

You should read these as follows: in any structure $\mathbf{S}$, if $X$ is true in $\mathbf{S}$ and $Y$ is true in $\mathbf{S}$, then $X \wedge Y$ is true in $\mathbf{S}$. If $X$ is true in $\mathbf{S}$ and $Y$ is false in $\mathbf{S}$, then $X \wedge Y$ is is false in $\mathbf{S}$, and so on, for each line of each truth-table. 

There are other ways to specify these same truth-functions. One is to arithmetize the relation between the input(s) and the output using $1$ for true and $0$ for false. This looks nice for some connectives, but less nice for others. Thus: 

\begin{enumerate}
	\item $v'(\neg X)=1-v'(X)$;
	\item $v'(X \wedge Y)=v'(X)\times v'(Y)=\text{MAX}(v'(X),v'(Y))$;
	\item $v'(X \vee Y)=1-((1-v'(X)) \times (1-v'(Y)))=\text{MIN}(v'(X), v'(Y))$;
	\item $v'(X \rightarrow Y)=1 - (v'(X) \times (1-v'(Y))$. 
\end{enumerate}

\begin{remark}
In the above, $\text{MIN}$ means the function that outputs the minimum value of two values, and $\text{MAX}$ is the function that outputs the maximum value of two values. In terms of this, the meaning of our connectives is simple, since the value of $\wedge$ is just the maximum function on $1$ and $0$, and the value of $\vee$ the minimum. However, as demonstrated, you do not need to invoke these functions to define $v'$. 
\end{remark}

We can check if the four tables in Figure \ref{ttt} match our tables in Figure \ref{tto} by computing the right side with our equations. And indeed, they do match! 

\begin{figure}[h]
\begin{center}
\begin{minipage}{0.45\textwidth}
		\begin{tabular}{|c|c|c|}
			\hline
			$X$ & $Y$ & $X \wedge Y$\\ \hline
			$1$ & $1$ & $1\times 1=1$\\
			$1$ & $0$ & $1 \times 0=0$\\
			$0$ & $1$ & $0 \times 1=0$\\
			$0$ & $0$ & $0\times 0=0$\\ \hline
		\end{tabular}
\end{minipage}
\begin{minipage}{0.45\textwidth}
		\begin{tabular}{|c|c|c|}
			\hline
			$X$ & $Y$ & $X \vee Y$\\ \hline
			$1$ & $1$ & $1-((1-1) \times (1-1))=1$\\
			$1$ & $0$ & $1-((1-1) \times (1-0))=1$\\
			$0$ & $1$ & $1-((1-0) \times (1-1))=1$\\
			$0$ & $0$ & $1-((1-0) \times (1-0))=0$\\\hline
		\end{tabular}
\end{minipage}

\vspace{\baselineskip}
\begin{minipage}{0.45\textwidth}
		\begin{tabular}{|c|c|c|}
			\hline
			$X$ & $Y$ & $X \rightarrow Y$\\ \hline
			$1$ & $1$ & $1-(1 \times (1-1))=1$\\
			$1$ & $0$ & $1-(1 \times (1-0))=0$\\
			$0$ & $1$ & $1-(0 \times (1-1))=1$\\
			$0$ & $0$ & $1-(0 \times (1-0))=1$\\ \hline
		\end{tabular}
\end{minipage}
\begin{minipage}{0.45\textwidth}
		\begin{tabular}{|c|c|}
			\hline
			$X$ & $\neg X$\\ \hline
			$1$ & $1-1=0$\\
			$0$ & $1-0=1$\\ \hline
		\end{tabular}
\end{minipage}
\end{center}
\caption{Truth tables a different way}
\label{ttt}
\end{figure}

Finally, we can put the above ideas in line with our previous results, and specify it as such:

\begin{enumerate}
	\item $\mathbf{S} \models \neg X$ if, and only if, $\mathbf{S} \not\models X$;
	\item $\mathbf{S} \models (X \wedge Y)$ if, and only if, $\mathbf{S} \models X$ and $\mathbf{S}\models Y$;
	\item $\mathbf{S} \models (X \vee Y)$ if, and only if, $\mathbf{S} \models X$ or $\mathbf{S}\models Y$ (or both);
	\item $\mathbf{S} \models (X \rightarrow Y)$ if, and only if, if $\mathbf{S} \models X$, then $\mathbf{S} \models Y$. 
\end{enumerate}

Here is some helpful information as to how to read the above specifications. On the left hand side of the `if, and only if' connective, you always find more complex formulas, while on the right hand side, you always find less complex formulas. Reading from left to right, you can determine when the more complex formula must be true in a structure. For example, $\neg X$ must be true in a structure provided $X$ is false in that structure. Reading from right to left, you can determine the value of the more complex formula if the conditions on the right side hold for less complex ones. So if $X$ and $Y$ are both true in $\mathbf{S}$, $X \wedge Y$ will also be true. 

It is important that these specifications allow one to determine both truth \textit{and} falsity for any complex formula depending on the truth \textit{or} falsity of some simpler formulas, and vice versa. But this may not be apparent at first. 

Suppose $\mathbf{S} \not\models X \vee Y$, i.e., it is false in $\mathbf{S}$. Now it is specified what simpler formulas need to be true in order for $X \vee Y$ to be true. So how do we determine what needs to happen for it to be false in $\mathbf{S}$? Well, all we have to do is negate the right hand side, and see what's left. In particular:
%
\begin{quote}
	$\mathbf{S} \not\models X \vee Y$ if, and only if, it is not the case that [$\mathbf{S} \models X$ or $\mathbf{S}\models Y$ (or both)].
\end{quote}
%
Now this states that $\mathbf{S} \not\models X \vee Y$ if neither $X$ nor $Y$ is true in $\mathbf{S}$, since all three other possibilities \textit{would} make it true. And indeed, this is just what the truth-table says!

Similarly, but from the other way around, suppose $\mathbf{S} \not\models X$ and $\mathbf{S} \models Y$. Well, since $\mathbf{S} \models X \wedge Y$ if, and only if, $\mathbf{S} \models X$ and $\mathbf{S} \models Y$, we have:

\begin{quote}
	$\mathbf{S} \not\models X \wedge Y$ if, and only if, it is not the case that [$\mathbf{S} \models X$ and $\mathbf{S} \models Y$]. 
\end{quote}

If it is not the case that [$\mathbf{S} \models X$ and $\mathbf{S} \models Y$], then either $X$ or $Y$ or both are false in $\mathbf{S}$. So in particular, if $\mathbf{S} \not\models X$ and $\mathbf{S} \models Y$, then $\mathbf{S} \not\models X \wedge Y$. 

\fpboxstar{
One way to think about this is by simply noting that $\not\models$ is just the negation of $\models$. So if the definition specifies when something is modeled, then it will \textit{not} be modeled precisely when that specification is \textit{not} met. That is, once the left side of the biconditional is negated, the right side needs to be too. It is very much akin to multiplying by $-1$ in an equation. This is a very fundamental fact that goes for every biconditional; if you negate both sides of a true biconditional, you get a true biconditional.
}

From now on, we will be using this type of specification to talk about the values of complex formulas. At times, we may refer back to truth-tables as a helpful reference for those who already know how truth-tables work. Don't worry if you are not familar with truth-tables. They do not give any more information than what can already be found in our style of specification. 

\subsubsection{Computing with complex formulas}

Let's turn back the wheel of time to the beginning of this book, where we specified the language of arithmetic expressions $\mathcal{L}_{AE}$. You may remember how we emphasized that the syntactic trees for those expressions give you an order of computation, based on how the parentheses are configured in the formula. If you forgot, go back to page \pageref{syntrcom} to refresh your memory. In fact, the situation is the same with the expressions of $\mathcal{L}_0$, except instead of $+$, $-$ and $\times$, we have our connectives, and instead of numbers, we have atomic formulas which themselves require computation. And formulas are either true or false. But it's the same. 

Once again, take a structure $\mathbf{S}=\oset{\mathbf{D}, I}$ with the domain $\mathbf{D}=\set{\mathbf{a}, \mathbf{b}, \mathbf{c}, \mathbf{d}}$, and an interpretation function $I$ such that:

\begin{enumerate}
	\item $I(a)=\mathbf{a}$, $I(b)=\mathbf{b}$, $I(c)=\mathbf{c}$, $I(d)=\mathbf{d}$; 
	\item 
	\begin{enumerate}
		\item $I(P)=\{\mathbf{a}, \mathbf{d}\}$;
		\item $I(Q)=\set{\oset{\mathbf{a}, \mathbf{c}}, \oset{\mathbf{d}, \mathbf{a}}, \oset{\mathbf{a}, \mathbf{d}}}$;
		\item $I(R)=\set{\oset{\mathbf{a}, \mathbf{b}, \mathbf{c}}, \oset{\mathbf{b}, \mathbf{c}, \mathbf{b}}, \oset{\mathbf{b}, \mathbf{b}, \mathbf{b}}}$.
	\end{enumerate} 
\end{enumerate}

We already know a bunch about what truth-values various formulas get in the structure $\mathbf{S}$. Now, we can go on to talk about the values of more complex formulas, built out of our connectives. 

Suppose you want to find out whether $(P(a) \vee P(c)) \wedge Q(a, c)$ is true in $\mathbf{S}$. Let's quickly draw up a syntax tree for this formula:

\begin{center}
\begin{forest}
[{$(P(a) \vee P(c)) \wedge Q(a, c)$}
	[{$P(a) \vee P(c)$}
		[{$P(a)$}
		]
		[{$P(c)$}
		]
	]
	[${Q(a, c)}$
	]
]
\end{forest}
\end{center}

As with the example regarding $\mathcal{L}_{AE}$, we start from the leaves of our tree (remember that it is upside down). Now in general, you would first have to compute whether $P(a)$, $P(c)$, and $Q(a, c)$ are true in $\mathbf{S}$, but we will not revisit this issue, since this was already done above. 

We had the following facts:

\begin{enumerate}
	\item $\mathbf{S} \models P(a)$;
	\item $\mathbf{S} \not\models P(c)$;
	\item $\mathbf{S} \models Q(a, c)$.
\end{enumerate}

We can substitute these values for the relevant formulas in our tree. Thus: 

\begin{center}
	\begin{forest}
[{$(P(a) \vee P(c)) \wedge Q(a, c)$}
	[{$P(a) \vee P(c)$}
		[{$T$}
		]
		[{$F$}
		]
	]
		[${T}$
	]
]
	\end{forest}
\end{center}

Then, we need to proceed on the left side first, so we substitute the relevant values one level up:

\begin{center}
\begin{forest}
[{$(P(a) \vee P(c)) \wedge Q(a, c)$}
	[{$T \vee F$}
	]
	[${T}$
	]
]
\end{forest}
\end{center}

Now given how the connective $\vee$ was defined above, we can compute from $T \vee F$ the value $T$, since $\mathbf{S} \models X \vee Y$ if $\mathbf{S} \models X$, even if $\mathbf{S} \not\models Y$. So we have:

\begin{center}
\begin{forest}
[{$(P(a) \vee P(c)) \wedge Q(a, c)$}
	[{$T$}
	]
	[${T}$
	]
]
	\end{forest}
\end{center}

Substituting again, we have:
%
\[
T \wedge T
\]
%
Invoking the rule for the connective $\wedge$, we get $T$ as the final value, so 
%
\[
\mathbf{S} \models (P(a) \vee P(c)) \wedge Q(a, c).
\]

\fpboxstar{
Note that this is a handy way to compute the values of formulas, but you should not confuse things like $T \vee F$ for formulas of the language, since they are not. In general, what we are doing in this computation is systematically replacing our formulas with their \textit{values in} $\mathbf{S}$. In other words, it is just a compact representation of something more verbose (see immediately below).
}

There are several ways of going about computing the values of formulas. In presentation, it may look something like this: 

\begin{quote}
	Take the formula $(P(a) \vee P(c)) \wedge Q(a, c)$. By our previous results, $\mathbf{S} \models P(a)$, $\mathbf{S} \not\models P(c)$, and $\mathbf{S}\models Q(a, c)$. By definition of $\vee$, $\mathbf{S} \models P(a) \vee P(c)$, since $\mathbf{S} \models P(a)$. Then, by definition of $\wedge$, $\mathbf{S} \models (P(a) \vee P(c)) \wedge Q(a, c)$, since $\mathbf{S} \models P(a) \vee P(c)$, and $\mathbf{S} \models Q(a,c)$. This is what we wanted to show. \label{expref}
\end{quote}

In fact, if you really want to go crazy, you can use the equations above, and produce something like this: 
%
\[
(1 -((1-1) \times (1-0))) \times 1=1
\]
%
\begin{quote}%
Now $1-1=0$, $1-0=1$, so we get $0 \times 1$, which is $0$, which we subtract from $1$, which gets us $1$, which we multiply by $1$ to get $1$. Or true. 
\end{quote}

This is not a thing we will be doing going further. 

\begin{exc}
Take the structure $\mathbf{S}=\langle \mathbf{D}, I\rangle$ exactly as specified above. Determine the truth-value of the following formula, giving a detailed explanation, \textit{including} how the atomic formulas get their truth-value. 

\[
(Q(a, c) \vee \neg R(a, b, c)) \rightarrow \neg R(a, c, b)
\]
\end{exc}

\begin{remark}
	In this exercise, you are essentially asked to combine two types of explanations, from the values of predicates and constants to the values of atomic formulas, and then from values of formulas to values of formulas. The latter was just demonstrated. For the former, some proofs were already provided, and some make up Exercise \ref{atomicvalue}.
\end{remark}


\subsubsection{Computing from formulas up}

We do not always have to consider how exactly the atomic formulas are specified in each case. Instead, we can talk more abstractly about assigning some truth-value to some specific formula $X$ of the language, and some other truth-value to some specific formula $Y$ of the language (and so on), and then see what truth-values one gets in a structure if we combine them in various ways. Indeed, doing this is equivalent to doing \textit{propositional} or \textit{sentential} logic, and specifically, drawing up more general truth-tables. Again, this you may already be familiar with. 

For example, suppose $X$ is any formula, and $Y$ is any formula, and consider the formula $X \wedge \neg Y$. We do not know what these variables stand for (other than that they are formulas), so we cannot specify an exact structure for them, in which they may be true or false. But what we can do is \textit{assume} that there is a certain structure in which, say $X$ is true and $Y$ is false, and then consider whether $X \wedge \neg Y$ is true or false \textit{as a result} in a structure. 

\fpboxstar{
Actually, what we are considering here is not just one structure but many; all those in which $X$ is true and $Y$ is false (for each possible choice of formula for the variables $X$ and $Y$). But by abstracting away from the specifics, we do not need to worry about this. 
}

Now the question is: is $X \wedge \neg Y$ true if $X$ is true and $Y$ is false in a structure? You might already see that in such a case, $X \wedge \neg Y$ is, in fact, true. Here is how it would go:

\begin{quote}
Suppose there is a structure $\mathbf{S}$ such that $\mathbf{S} \models X$ but $\mathbf{S} \not\models Y$. By the above definition, $\mathbf{S} \models \neg Y$ provided $\mathbf{S} \not\models Y$, so $\mathbf{S} \models \neg Y$. Then, again, by definition, $\mathbf{S} \models X \wedge \neg Y$, provided $\mathbf{S} \models X$ and $\mathbf{S} \models \neg Y$, which we already know, so $\mathbf{S} \models X \wedge \neg Y$
\end{quote}

This reasoning is the exact same as the following vertical fragment of a generalized truth-table:

\begin{center}
\begin{tabular}{c|c|c|c}
$X$ & $Y$ & $\neg Y$ & $X \wedge \neg Y$ \\\hline
$T$ & $F$ & $T$ & $T$
\end{tabular}
\end{center}

\begin{exc}
Determine the truth-value and construct detailed explanations (as opposed to truth-tables) for the following formulas, assuming $\mathbf{S} \models X$, $\mathbf{S} \not\models Y$, and $\mathbf{S} \models Z$:

\begin{enumerate}
	\item $\neg (X \vee Y) \rightarrow Z$;
	\item $(\neg X \wedge Y) \vee \neg Z$;
	\item $Z \rightarrow (X \wedge \neg X)$;
	\item $Y \rightarrow (Z \vee \neg Z)$;
	\item $\neg (X \wedge Z) \rightarrow (\neg X \vee \neg Z)$;
	\item $(Z \rightarrow Y) \rightarrow (\neg Z \vee Y)$.
\end{enumerate}
\end{exc}


\subsubsection{Putting it all together}

We are now in the position to formulate our whole semantics in one fell swoop. This is usually done in more advanced works at the very beginning (or not at all). You shall now be able to read those definitions with confidence. 

\begin{defn} \label{models}
	A structure $\mathbf{S}$ is a pair $\oset{\mathbf{D}, \mathbf{I}}$, where $\mathbf{D}$ is any set, and $\mathbf{I}$ is a function from the constants and predicates of $\mathcal{L}_0$ (i.e., $\mathsf{CON}_{\mathcal{L}_0} \cup \mathsf{PRED}_{\mathcal{L}_0}$) such that:
	%
	\begin{enumerate}
		\item if $c$ is any constant of $\mathcal{L}_0$, $\mathbf{I}(c) \in \mathbf{D}$, and;
		\item if $P^n$ is any predicate  of arity $n$ of $\mathcal{L}_0$, $\mathbf{I}(P^n)=\mathbf{R}$, where $\mathbf{R} \subseteq \mathbf{D}^n$. 
	\end{enumerate}
	%
	For any formulas $X, Y, Z$ of $\mathcal{L}_0$:
	
	\begin{enumerate}
	\item if $X$ is of form $P^n(c_1, ..., c_n)$, $\mathbf{S} \models P^n(c_1, ..., c_n)$ if, and only if, $\oset{c_1, ..., c_n} \in I(P^n)$;
	\item if $X$ is of form $\neg Y$, $\mathbf{S} \models \neg Y$ if, and only if, $\mathbf{S} \not\models Y$;
	\item if $X$ is of form $Y \wedge Z$, $\mathbf{S} \models Y \wedge Z$ if, and only if, $\mathbf{S} \models Y$ and $\mathbf{S}\models Z$;
	\item if $X$ is of form $Y \vee Z$,  $\mathbf{S} \models Y \vee Z$ if, and only if, $\mathbf{S} \models Z$ or $\mathbf{S}\models Y$ (or both);
	\item if $X$ is of form $Y \rightarrow Z$, if $\mathbf{S} \models Y$, then $\mathbf{S} \models Z$. 
	\end{enumerate}
	
	If $\mathbf{S} \models P(c_1, ..., c_n)$, we say $\mathbf{S}$ \textit{models} $P(c_1, ..., c_n)$, or \textit{is a model of} $P(c_1, ..., c_n)$. Alternatively, we say $P(c_1, ..., c_n)$ is \textit{true in} $\mathbf{S}$.
\end{defn}

Congratulations, this concludes the semantics of $\mathcal{L}_0$.

\fpboxstar{From now on, we will omit writing out `if, and only if' each and every time. Instead, we will opt for the abbreviation `\textit{iff}' (in italics).}